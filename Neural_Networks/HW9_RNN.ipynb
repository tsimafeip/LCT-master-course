{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13935de6-9e28-4f76-83da-6f72218e3bef",
      "metadata": {
        "id": "13935de6-9e28-4f76-83da-6f72218e3bef"
      },
      "source": [
        "# NNIA Assignment 9\n",
        "\n",
        "**DEADLINE: 26. 1. 2022 08:00 CET**\n",
        "Submission more than 10 minutes past the deadline will **not** be graded!\n",
        "\n",
        "- Trevor Atkins & trat00001@uni-saarland.de:\n",
        "- Tsimafei Prakapenka & tspr00001@uni-saarland.de:\n",
        "- Hours of work per person: Prakapenka ~9.5h Atkins ~4.5h\n",
        "- Group nickname: PraAt\n",
        "\n",
        "# Submission Instructions\n",
        "\n",
        "**IMPORTANT** Please make sure you read the following instructions carefully. If you are unclear about any part of the assignment, ask questions **before** the assignment deadline. All course-related questions can be addressed on the course **[Piazza Platform](https://piazza.com/class/kvc3vzhsvh55rt)**.\n",
        "\n",
        "* Assignments are to be submitted in a **team of 2**.\n",
        "* Please include your **names**, **ID's**, **Teams usernames**, and **approximate total time spent per person** at the beginning of the Notebook in the space provided\n",
        "* Make sure you appropriately comment your code wherever required.\n",
        "* Your final submission should contain this completed Jupyter Notebook, including the bonus question (if you attempt it), and any necessary Python files.\n",
        "* Do **not** submit any data or cache files (e.g. `__pycache__`).\n",
        "* Upload the **zipped** folder (*.zip* is the only accepted extension) in **Teams**.\n",
        "* Only **one member** of the group should make the submisssion.\n",
        "* **Important** please name the submitted zip folder as: `Name1_id1_Name2_id2.zip`. The Jupyter Notebook should also be named: `Name1_id1_Name2_id2.ipynb`. This is **very important** for our internal organization epeatedly students fail to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "feef094d-d753-4e3d-b5ef-d720810dae31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feef094d-d753-4e3d-b5ef-d720810dae31",
        "outputId": "3481f160-60be-46b3-8ce1-b6082057f5fe"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c30bb375-058c-4253-aa17-7adfa4ea2ab6",
      "metadata": {
        "id": "c30bb375-058c-4253-aa17-7adfa4ea2ab6"
      },
      "source": [
        "# 1 Diacritization (9 points)\n",
        "\n",
        "The English alphabet has 26 letters. This is not the case for Czech (and many more European languages), which has many more extra letters, namely those with a simple accent (čárka, lit. \"short line segment\"): `áéíýúó`, those with a little hook (háček): `ěčšžř` and those with a circle (kroužek) `ů`.\n",
        "They change the pronounciations of the words (mostly palatalization) and also distinguish words (there are many words which differ only by diacritics). \n",
        "Typing words without these accents is considered to be rude (and annoying to read).\n",
        "Imagine you've been tasked by a telecommunication company to come up with a system to automatically add all the accents correctly given a word without accents.\n",
        "Each line in the input contains two words: with and without accents, e.g.: `cerveneho červeného`.\n",
        "We provide the train/dev split for you (in separate files) and also a test file without correct answers.\n",
        "\n",
        "Your task is to create two neural networks character-level models that add the diacritization back to the word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ae1d3a",
      "metadata": {
        "id": "54ae1d3a"
      },
      "source": [
        "## 1.1 Baseline (1 points)\n",
        "\n",
        "- Plot the distribution of classes (there are 4)\n",
        "- Evaluate the accuracy of most common class classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2c8b7e43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c8b7e43",
        "outputId": "bba7fc39-840c-4617-813d-ee3a99be5e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /Users/tsimafeip/pythonProject/venv_m1/lib/python3.8/site-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eab3e779",
      "metadata": {
        "id": "eab3e779"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "LXWvFr7EvW_j",
      "metadata": {
        "id": "LXWvFr7EvW_j"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('solution.py'):\n",
        "    wget.download('https://raw.githubusercontent.com/tsimafeip/LCT-master-course/main/Neural_Networks/HW9_solution.py', 'solution.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6050e91f",
      "metadata": {
        "id": "6050e91f"
      },
      "outputs": [],
      "source": [
        "from solution import download_data_files\n",
        "\n",
        "train_filename = 'words_random_train.txt'\n",
        "dev_filename = 'words_random_dev.txt'\n",
        "test_filename = 'words_random_test_blind.txt'\n",
        "\n",
        "download_data_files([train_filename, dev_filename, test_filename])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d62a8930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62a8930",
        "outputId": "4feb77ab-a9d3-4be1-c9a3-8b608040b58f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['nájemřidiči', 'najemridici'] ['neodmyslitelné', 'neodmyslitelne'] transvestite\n"
          ]
        }
      ],
      "source": [
        "with open(train_filename, \"r\") as f:\n",
        "    train_data = list(map(str.split, f.readlines()))\n",
        "\n",
        "with open(dev_filename, \"r\") as f:\n",
        "    dev_data = list(map(str.split, f.readlines()))\n",
        "\n",
        "with open(test_filename, \"r\") as f:\n",
        "    test_data = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(train_data[1], dev_data[1], test_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eb910f12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb910f12",
        "outputId": "5a5ae59f-f554-4d43-b123-b7d5abde0a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'á': 1, 'é': 1, 'í': 1, 'ý': 1, 'ú': 1, 'ó': 1, 'ě': 2, 'č': 2, 'š': 2, 'ž': 2, 'ř': 2, 'ů': 3})\n"
          ]
        }
      ],
      "source": [
        "classlabel_to_classname = {0: 'nothing', 1: 'čárka', 2: 'háček', 3: 'kroužek'}\n",
        "classlabel_to_char = {1: ['á','é','í','ý','ú','ó'], 2: ['ě','č','š','ž','ř'], 3: ['ů']}\n",
        "\n",
        "# I use defaultdict to handle 0-class more smoothly\n",
        "char_to_classlabel = defaultdict(int)\n",
        "char_to_classlabel.update({\n",
        "    class_char: class_label \n",
        "    for class_label, class_chars in classlabel_to_char.items() \n",
        "    for class_char in class_chars\n",
        "})\n",
        "print(char_to_classlabel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "04aacd5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "04aacd5b",
        "outputId": "4799b64a-757e-4f43-d571-393482b435ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'nothing': 1021576, 'čárka': 78545, 'háček': 42728, 'kroužek': 2601}\n",
            "{'nothing': 0.8918556026015976, 'čárka': 0.06857130385438037, 'háček': 0.03730237024750098, 'kroužek': 0.002270723296521018}\n"
          ]
        }
      ],
      "source": [
        "from solution import distribution\n",
        "\n",
        "classname_to_count = distribution(\n",
        "    train_data=train_data, \n",
        "    classlabel_to_classname=classlabel_to_classname, \n",
        "    char_to_classlabel=char_to_classlabel,\n",
        ")\n",
        "print(classname_to_count)\n",
        "\n",
        "all_count = sum(classname_to_count.values())\n",
        "classname_to_percentage = {\n",
        "    class_name: class_count/all_count \n",
        "    for class_name, class_count in classname_to_count.items()\n",
        "}\n",
        "print(classname_to_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989c3fa0",
      "metadata": {
        "id": "989c3fa0"
      },
      "source": [
        "So, defaulting to nothing class will give us ~0.89 accuracy. Definitely not bad for a start."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6769e4c5",
      "metadata": {
        "id": "6769e4c5"
      },
      "source": [
        "## 1.2 Sliding windows (3 points)\n",
        "\n",
        "The first model is based on sliding windows, e.g. it considers the current character and two characters to the left and two characters to the right for context.\n",
        "You should also add padding tokens to the left and to the right so that you can classify the corner characters as well:\n",
        "\n",
        "```\n",
        "__Cer -> HOOK\n",
        "_cErv -> NOTHING\n",
        "ceRve -> NOTHING\n",
        "erVen -> NOTHING\n",
        "rvEne -> NOTHING\n",
        "veNeh -> NOTHING\n",
        "enEho -> SIMPLE ACCENT\n",
        "neHo_ -> NOTHING\n",
        "ehO__ -> NOTHING\n",
        "```\n",
        "\n",
        "\n",
        "Build a sliding-window neural network with the best architecture and hyperparameters and report your accuracies on train and dev datasets.\n",
        "Additionally, provide the output for the test file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "LV4GxxxnCDeR",
      "metadata": {
        "id": "LV4GxxxnCDeR"
      },
      "outputs": [],
      "source": [
        "#Global params\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PADDING_SYMBOL = \"_\"\n",
        "ALPHABET_SIZE = 26\n",
        "\n",
        "#Common NN params\n",
        "NUM_CLASSES = 4\n",
        "DROPOUT = 0.25\n",
        "\n",
        "# FFNN params\n",
        "FORCE_RETRAIN_FFNN = False\n",
        "FFNN_BEST_MODEL_PATH = 'best-model-ffnn.pt'\n",
        "FFNN_EPOCHS = 50\n",
        "FFNN_BATCH_SIZE = 128\n",
        "FFNN_INPUT_SIZE = 130\n",
        "\n",
        "# RNN params\n",
        "FORCE_RETRAIN_RNN = False\n",
        "RNN_BEST_MODEL_PATH = 'best-model-rnn.pt'\n",
        "RNN_EPOCHS = 30\n",
        "RNN_HIDDEN_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "tw4azp968ZXz",
      "metadata": {
        "id": "tw4azp968ZXz"
      },
      "outputs": [],
      "source": [
        "from solution import prepare_sliding_data\n",
        "\n",
        "X_train, y_train = prepare_sliding_data(train_data, char_to_classlabel)\n",
        "X_dev, y_dev = prepare_sliding_data(dev_data, char_to_classlabel)\n",
        "X_test = prepare_sliding_data(test_data, char_to_classlabel)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ba638fd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba638fd4",
        "outputId": "421bf7f4-511a-4746-efc2-ed1208bafa47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('__nei', 0, 1145450, 190499, 169901)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0], y_train[0], len(X_train), len(X_dev), len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e948567d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e948567d",
        "outputId": "9c279fcc-77a6-4b55-e065-0c0d5730108f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__nei 130\n"
          ]
        }
      ],
      "source": [
        "from solution import one_hot_encode\n",
        "\n",
        "sample_encoding = one_hot_encode(X_train[0])\n",
        "print(X_train[0], len(sample_encoding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "80728d95",
      "metadata": {
        "id": "80728d95"
      },
      "outputs": [],
      "source": [
        "from solution import CustomSlidingDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = CustomSlidingDataset(X_train, y_train)\n",
        "validation_dataset = CustomSlidingDataset(X_dev, y_dev)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=FFNN_BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=FFNN_BATCH_SIZE*4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "CGtODtRQ6C4j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGtODtRQ6C4j",
        "outputId": "47c88d29-3d4c-4e87-f240-985e2d2bdb5b"
      },
      "outputs": [],
      "source": [
        "from solution import run_train_and_val_ffnn, DiacriticFFNN, validation_loop_ffnn\n",
        "\n",
        "\n",
        "if not FORCE_RETRAIN_FFNN and not os.path.isfile(FFNN_BEST_MODEL_PATH):\n",
        "    wget.download(f'https://raw.githubusercontent.com/tsimafeip/LCT-master-course/main/Neural_Networks/HW9_data/{FFNN_BEST_MODEL_PATH}', FFNN_BEST_MODEL_PATH)\n",
        "    model = DiacriticFFNN().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(FFNN_BEST_MODEL_PATH, map_location=DEVICE))\n",
        "    # run short validation to report metrics and check if model is working\n",
        "    ffnn_best_metrics = \\\n",
        "        validation_loop_ffnn(model=model, \n",
        "                             dataloader=validation_dataloader, \n",
        "                             loss_fn = nn.CrossEntropyLoss())\n",
        "    print()\n",
        "    print(ffnn_best_metrics)\n",
        "\n",
        "if FORCE_RETRAIN_FFNN or not os.path.isfile(FFNN_BEST_MODEL_PATH):\n",
        "    model = DiacriticFFNN()\n",
        "    ffnn_best_model_path, ffnn_best_epoch, ffnn_best_metrics = \\\n",
        "        run_train_and_val_ffnn(model, train_dataloader,\n",
        "                               validation_dataloader,\n",
        "                               epochs=FFNN_EPOCHS,\n",
        "                               best_model_path=FFNN_BEST_MODEL_PATH)\n",
        "    \n",
        "    print()\n",
        "    print(ffnn_best_model_path, ffnn_best_epoch, ffnn_best_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "LQxwS080I8L4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQxwS080I8L4",
        "outputId": "d99c265d-7e55-4656-fbc7-281978cd7053"
      },
      "outputs": [],
      "source": [
        "# from solution import predict_result_fnn\n",
        "          \n",
        "# predict_result_fnn(X_test, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b2d1ba1",
      "metadata": {
        "id": "5b2d1ba1"
      },
      "source": [
        "## 1.3 RNN (5 points)\n",
        "\n",
        "Secondly, build a character-level recurrent neural network many (n) to many (n) which performs the classification:\n",
        "```\n",
        "cerveny -> HNNNNNANN\n",
        "```\n",
        "\n",
        "Be careful, this will require you to either pad the input sequence (then you will also need to backpropagate only from the original sequence and disregard padded values) or use some other trick.\n",
        "\n",
        "You can use all the tricks you know for both models. For the RNN-based one, you can use non-vanilla RNN cells (such as LSTM or GRU). The recurrent part should be followed-up with a classification FFNN. Again, try to find the best architecture and hyperparameters, report train and dev results.\n",
        "\n",
        "In both cases, describe in text the architecture of your models.\n",
        "\n",
        "Provide also an output for the test file, one word per file, with diacritics (e.g. `červeného`). This is mandatory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "06c81049",
      "metadata": {
        "id": "06c81049"
      },
      "outputs": [],
      "source": [
        "from solution import prepare_rnn_data\n",
        "\n",
        "X_train_rnn, y_train_rnn = prepare_rnn_data(train_data, char_to_classlabel)\n",
        "X_dev_rnn, y_dev_rnn = prepare_rnn_data(dev_data, char_to_classlabel)\n",
        "X_test_rnn = prepare_rnn_data(test_data, char_to_classlabel)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "51401bc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51401bc0",
        "outputId": "d2d9b890-de9f-4ac8-f6dc-f8b62a00003b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(90000, 15000, 13376, tensor([0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0]))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train_rnn), len(X_dev_rnn), len(X_test_rnn), y_train_rnn[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7EwSlaDFKqWt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EwSlaDFKqWt",
        "outputId": "6410f011-5c61-4cd8-b141-d64a88da5556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([11, 26]) torch.Size([11, 4])\n"
          ]
        }
      ],
      "source": [
        "from solution import DiacriticsRNN\n",
        "\n",
        "rnn_model = DiacriticsRNN(input_size=ALPHABET_SIZE, hidden_size=RNN_HIDDEN_SIZE,\n",
        "                          output_size=NUM_CLASSES, dropout=DROPOUT)\n",
        "\n",
        "# check if forward path works\n",
        "for input_tensor in X_train_rnn:\n",
        "    with torch.no_grad():\n",
        "        model_output = rnn_model.forward(input_tensor)\n",
        "        print(input_tensor.shape, model_output.shape)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "72403c0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "72403c0d",
        "outputId": "8f97b6b3-d49f-4e1e-9255-c0fa3cae9d43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15000it [00:04, 3180.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "{'loss': 0.16698830337333978, 'accuracy': 0.9373330043727264, 'predicted_labels': defaultdict(<class 'int'>, {0: 177305, 2: 3462, 1: 9723, 3: 9}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from solution import run_train_and_val_rnn, validation_loop_rnn\n",
        "\n",
        "if not FORCE_RETRAIN_RNN and not os.path.isfile(RNN_BEST_MODEL_PATH):\n",
        "    wget.download(f'https://raw.githubusercontent.com/tsimafeip/LCT-master-course/main/Neural_Networks/HW9_data/{RNN_BEST_MODEL_PATH}', RNN_BEST_MODEL_PATH)\n",
        "    rnn_model = DiacriticsRNN(input_size=ALPHABET_SIZE, hidden_size=RNN_HIDDEN_SIZE,\n",
        "                              output_size=NUM_CLASSES, dropout=DROPOUT)\n",
        "    rnn_model.load_state_dict(torch.load(RNN_BEST_MODEL_PATH, map_location=DEVICE))\n",
        "    # run short validation to report metrics and check if model is working\n",
        "    best_rnn_metrics = \\\n",
        "        validation_loop_rnn(model=rnn_model, x_data=X_dev_rnn, \n",
        "                            y_data=y_dev_rnn, loss_fn = nn.CrossEntropyLoss())\n",
        "    \n",
        "    print()\n",
        "    print(best_rnn_metrics)\n",
        "\n",
        "if FORCE_RETRAIN_RNN or not os.path.isfile(RNN_BEST_MODEL_PATH):\n",
        "    rnn_model = DiacriticsRNN(input_size=ALPHABET_SIZE, hidden_size=RNN_HIDDEN_SIZE,\n",
        "                              output_size=NUM_CLASSES, dropout=DROPOUT)\n",
        "\n",
        "    path_to_best_rnn_model_file, best_rnn_epoch, best_rnn_metrics = \\\n",
        "        run_train_and_val_rnn(rnn_model, X_train_rnn,\n",
        "                              y_train_rnn, X_dev_rnn,\n",
        "                              y_dev_rnn, epochs=RNN_EPOCHS,\n",
        "                              path_to_best_model_file=RNN_BEST_MODEL_PATH)\n",
        "    \n",
        "    print()\n",
        "    print(path_to_best_rnn_model_file, best_rnn_epoch, best_rnn_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44c7bcc6",
      "metadata": {},
      "source": [
        "Comments:\n",
        "1. I have stopped training after 12 epochs.\n",
        "2. Gradient accumulation does not work for me:\n",
        "```\n",
        "RNN_BATCH_SIZE = 32\n",
        "model.train()\n",
        "for batch_idx, (x_tensor, gold_label_tensor) in enumerate(tqdm(zip(x_data, y_data))):\n",
        "    # Compute prediction and loss\n",
        "    pred_output = model(x_tensor)\n",
        "    loss = loss_fn(pred_output, gold_label_tensor) / RNN_BATCH_SIZE\n",
        "    loss.backward()\n",
        "\n",
        "    if ((batch_idx + 1) % RNN_BATCH_SIZE == 0) or (batch_idx + 1 == dataset_size):\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "Epoch 1\n",
        "-------------------------------\n",
        "Train metrics:  {'loss': 0.037127886973238655, 'accuracy': 0.6176297524990179, 'predicted_labels': defaultdict(<class 'int'>, {1: 267872, 3: 102822, 2: 7549, 0: 767207}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
        "Validation metrics:  {'loss': 0.6670510955462853, 'accuracy': 0.8931700428873642, 'predicted_labels': defaultdict(<class 'int'>, {0: 190499}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
        "\n",
        "-------------------------------\n",
        "1\n",
        "90000it [02:18, 651.34it/s]\n",
        "15000it [00:04, 3333.32it/s]\n",
        "\n",
        "Epoch 2\n",
        "-------------------------------\n",
        "Train metrics:  {'loss': 0.014869989560646677, 'accuracy': 0.8918556026015976, 'predicted_labels': defaultdict(<class 'int'>, {0: 1145450}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
        "Validation metrics:  {'loss': 0.4108426091613869, 'accuracy': 0.8931700428873642, 'predicted_labels': defaultdict(<class 'int'>, {0: 190499}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
        "\n",
        "Epoch 3\n",
        "-------------------------------\n",
        "Train metrics:  {'loss': 0.012825845986056244, 'accuracy': 0.8918556026015976, 'predicted_labels': defaultdict(<class 'int'>, {0: 1145450}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
        "Validation metrics:  {'loss': 0.3944781747162342, 'accuracy': 0.8931700428873642, 'predicted_labels': defaultdict(<class 'int'>, {0: 190499}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
        "\n",
        "-------------------------------\n",
        "3\n",
        "90000it [02:16, 660.07it/s]\n",
        "15000it [00:04, 3446.35it/s]\n",
        "\n",
        "Epoch 4\n",
        "-------------------------------\n",
        "Train metrics:  {'loss': 0.012440418811670195, 'accuracy': 0.8918556026015976, 'predicted_labels': defaultdict(<class 'int'>, {0: 1145450}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
        "Validation metrics:  {'loss': 0.38559575219663483, 'accuracy': 0.8931700428873642, 'predicted_labels': defaultdict(<class 'int'>, {0: 190499}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5a3c01f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "5a3c01f8",
        "outputId": "ea757031-ae04-4a0e-fa30-5d669a75d758"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "13376it [00:04, 2780.82it/s]\n"
          ]
        }
      ],
      "source": [
        "from solution import predict_result_rnn      \n",
        "          \n",
        "predict_result_rnn(test_data, X_test_rnn, rnn_model, path_to_best_model=RNN_BEST_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bfbdf7d-6c39-4eba-8b18-8cf8b8d86d8b",
      "metadata": {
        "id": "0bfbdf7d-6c39-4eba-8b18-8cf8b8d86d8b"
      },
      "source": [
        "# 2 Theory (1 point)\n",
        "\n",
        "Find NLP tasks (apart form diacritization) that match the following RNN architecture and describe them in detail:\n",
        "- Many (n) to many (n)\n",
        "- Many (n) to many (m), m $\\neq$ n\n",
        "- Many (n) to one\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64cd25f",
      "metadata": {
        "id": "f64cd25f"
      },
      "source": [
        "- Many (n) to many (n) - POS-tagging <br>\n",
        "This RNN has synced sequence input and synced sequence output where both lengths are equal. For POS-tagging for example, word tokennization is processed on a sentence and a POS will be tagged for each token. \n",
        "Example: sentence: computational linguistics is interdisciplinary\n",
        "tokenization: \\['computational', 'linguistics', 'is', 'interdisciplinary'\\]\n",
        "pos-tag: \\['adjective', 'noun', 'verb', 'adjective'\\] Each output node can measure the loss, so averaging the losses (sequence loss) can be used for training. Padding tokens may need to be considered for removal.\n",
        "- Many (n) to many (m), m $\\neq$ n - Machine Translation <br>\n",
        "This RNN has sequence input and sequence output. For machine translation, the RNN has LSTM layers or architecture, where there is a self-loop with gated weights (forget gate, external input gate, and output gate). Cells are connected recurrently to each other, replacing the usual hidden units of ordinary recurrent networks. The layer is also split into two parts: the encoder that takes the input and the decoder that reads and translates to the output target language. \n",
        "- Many (n) to one - Sentiment Analysis <br>\n",
        "This RNN has sequence input and fixed size (one) output. For sentiment analysis, the input would be a sequence like a sentence and the output would be a classification label of positive or negative sentiment. The sentence would be converted into a numerical vector using an embedding layer and encoded with a bidirectional RNN. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6226bf7d-b8e9-4b3e-bf9f-d237b3ce8f41",
      "metadata": {
        "id": "6226bf7d-b8e9-4b3e-bf9f-d237b3ce8f41"
      },
      "source": [
        "# Final remarks\n",
        "\n",
        "## Accuracies\n",
        "\n",
        "It is important that your models perform well:\n",
        "\n",
        "||Dev accuracy|\n",
        "|-|-|\n",
        "|Minimum for full points on sliding windows|96.0%|\n",
        "|Minimum for full points on RNN|97.0%|\n",
        "|SoTA [Náplava et al. 2021](https://ufal.mff.cuni.cz/pbml/116/art-naplava-straka-strakova.pdf)|99.2% (different dataset)|\n",
        "|Best student solution from Charles University|99.1% (different dataset)|\n",
        "|A foreign student living in Prague for 5 years|92.0% (Vilém's personal feeling)|\n",
        "\n",
        "We will evaluate your test results and top 2 groups will get +2 points.\n",
        "The next 2 groups will get +1 point.\n",
        "\n",
        "## Runtime\n",
        "\n",
        "You don't need to use a GPU.\n",
        "The training on a 2019 high-end CPU takes 60 minutes.\n",
        "If you really need more compute power (you shouldn't need to need it) then you can use Google collab.\n",
        "Nevertheless, we suggest you to first work on a subset of data for a faster development loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "234378ea",
      "metadata": {
        "id": "234378ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: words_random_train.txt: No such file or directory\n",
            "rm: words_random_dev.txt: No such file or directory\n",
            "rm: words_random_test_blind.txt: No such file or directory\n",
            "rm: rnn_predictions.txt: No such file or directory\n",
            "rm: sliding_predictions.txt: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! rm $train_filename $dev_filename $test_filename rnn_predictions.txt sliding_predictions.txt $RNN_BEST_MODEL_PATH $FFNN_BEST_MODEL_PATH"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "assignment_9 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
