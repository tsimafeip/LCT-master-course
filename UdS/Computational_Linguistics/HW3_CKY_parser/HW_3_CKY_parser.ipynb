{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_3_CKY_parser.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCisy_0n1Ax2"
      },
      "source": [
        "# Context-free grammars and CKY parsing\n",
        "\n",
        "In this assignment, you get to experiment with large-scale context-free grammar (CFG) parsing using Python and NLTK. More specifically, we are asking you to implement the Cocke-Kasami-Younger (CKY) algorithm for bottom-up CFG parsing, and apply it to the word and the parsing problem of English.\n",
        "\n",
        "The ingredients are: the grammar, the test sentences, and the parser. We\n",
        "provide the first two ingredients. Please implement the parser from scratch,\n",
        "using NLTK only to represent grammars and trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqZn8PUf3zT4"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "The grammar stems from a project dealing with implementing spoken language processing systems in the airline industry – the Airline Travel Information System (ATIS). The ATIS CFG is available in the NLTK data package, together with 98 test sentences. You can initialize the resources this way:\n",
        "\n",
        "```\n",
        "grammar = nltk.data.load(\"grammars/large_grammars/atis.cfg\") # load the grammar\n",
        "s = nltk.data.load(\"grammars/large_grammars/atis_sentences.txt\") # load raw sentences\n",
        "t = nltk.parse.util.extract_test_sentences(s) # extract test sentences\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tViLlifd32Q-"
      },
      "source": [
        "import os\n",
        "\n",
        "from typing import List, Set, Union\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.grammar import CFG, Nonterminal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH4k-L5y31a4",
        "outputId": "4b50c6c0-1eda-4d22-c2a7-a2e331f6cb96"
      },
      "source": [
        "nltk.download('large_grammars')\n",
        "\n",
        "grammar = nltk.data.load(\"grammars/large_grammars/atis.cfg\") # load the grammar\n",
        "s = nltk.data.load(\"grammars/large_grammars/atis_sentences.txt\") # load raw sentences\n",
        "t = nltk.parse.util.extract_test_sentences(s) # extract test sentences"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package large_grammars to /root/nltk_data...\n",
            "[nltk_data]   Unzipping grammars/large_grammars.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qexEE2467d5"
      },
      "source": [
        "At this point, t is a list of 2-tuples, one per sentence. The first element of each tuple is the tokenized sentence, and the second element is the number\n",
        "of parses for that sentence according to the grammar. Note that this number\n",
        "can be zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qcqm14D4gmI",
        "outputId": "a8cc6057-a3f7-4637-d0b6-2b3e5c67739e"
      },
      "source": [
        "# explore loaded things\n",
        "print(*[line + '\\n' for line in s.split('\\n')][:15])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################################################################\n",
            " # The test set for the ATIS grammar is a randomly selected subset of \n",
            " # the DARPA ATIS3 development test set. \n",
            " # (The full ATIS corpus is distributed by the Linguistic Data Consortium). \n",
            " #\n",
            " # The original file can be found at URL:\n",
            " # http://www.informatics.sussex.ac.uk/research/groups/nlp/carroll/cfg-resources/\n",
            " #\n",
            " # Modified for NLTK by Peter Ljunglöf <peter.ljunglof@heatherleaf.se>\n",
            " # Each line begins with the number of parse trees according to the grammar.\n",
            " ##########################################################################################\n",
            " \n",
            " 2085 : i need a flight from charlotte to las vegas that makes a stop in saint louis .\n",
            " 1380 : what is the cheapest one way flight from phoenix to san diego that arrives in the morning on thursday june second .\n",
            " 50 : what is the cheapest one way flight from columbus to indianapolis .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjOf75rU4p6h",
        "outputId": "4d66d233-a06a-4972-ffc0-c5eeddf7c06a"
      },
      "source": [
        "grammar"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Grammar with 5517 productions>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_11hGn3h4DjX",
        "outputId": "38116be8-0819-4083-985d-63830e05d389"
      },
      "source": [
        "print('test corpus size: ', len(t))\n",
        "print('sample test item: ', t[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test corpus size:  98\n",
            "sample test item:  (['i', 'need', 'a', 'flight', 'from', 'charlotte', 'to', 'las', 'vegas', 'that', 'makes', 'a', 'stop', 'in', 'saint', 'louis', '.'], 2085)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsHjUAGU6_pw"
      },
      "source": [
        "NLTK already implements a number of parsing algorithms (see the documentation of nltk.parse for the list). You can try one to see if you loaded the grammar correctly:\n",
        "\n",
        "```\n",
        "# initialize the parser\n",
        "parser = nltk.parse.BottomUpChartParser(grammar) \n",
        "\n",
        "# parse all test sentences\n",
        "for sentence in t: \n",
        "    parser.chart_parse(sentence[0])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzDeYWTH3ytu"
      },
      "source": [
        "# initialize the parser\n",
        "base_parser = nltk.parse.BottomUpChartParser(grammar) \n",
        "\n",
        "# parse some sentences\n",
        "for sentence in t[:1]: \n",
        "    base_parser.chart_parse(sentence[0])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n6NtyJq2K2f"
      },
      "source": [
        "However, the NLTK version of the ATIS grammar is not in Chomsky normal form (CNF), which you will need for your CKY parser. Feel free to implement a conversion module for extra credit, but for your convenience, we have already converted the ATIS CFG into CNF; you can download it from http://www.coli.uni-saarland.de/~koller/materials/anlp/atis.zip. You\n",
        "can then read the grammar from the file using CFG.fromstring() and utilize\n",
        "the features of the nltk.grammar module on the resulting object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAtmUT_O55Aw"
      },
      "source": [
        "cnf_grammar_filename = 'atis-grammar-cnf.cfg'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFKjK1xm5CCb"
      },
      "source": [
        "%%capture\n",
        "if not os.path.isfile(cnf_grammar_filename):\n",
        "    ! wget http://www.coli.uni-saarland.de/~koller/materials/anlp/atis.zip\n",
        "    ! unzip atis.zip\n",
        "    ! rm atis.zip"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbQtfiCJ53hQ"
      },
      "source": [
        "with open(cnf_grammar_filename, 'r') as input_f:\n",
        "    lines = input_f.readlines()\n",
        "    cnf_grammar = CFG.fromstring(lines)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYB6JkWW6K-x"
      },
      "source": [
        "# initialize the parser\n",
        "parser = nltk.parse.BottomUpChartParser(cnf_grammar)\n",
        "\n",
        "# parse some sentences\n",
        "for sentence in t[:1]:\n",
        "    parser.chart_parse(sentence[0])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpm-v7DR2Vls"
      },
      "source": [
        "## Recognizer\n",
        "\n",
        "Implement the CKY algorithm and use it as a recognizer.\n",
        "\n",
        "That is, given an input sentence, the procedure should decide whether the\n",
        "sentence is in the language of the CFG or not. Test the recognizer on the\n",
        "ATIS test sentences (not all of which are grammatical), but also by feeding it\n",
        "other sentences to see whether it properly rejects ungrammatical sentences\n",
        "as well. Submit some of the ungrammatical sentences you tried."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXGPQ_5Du31O"
      },
      "source": [
        "```\n",
        "Data structure: Ch(i,k) eventually contains {A | A ⇒* wi ... wk-1} (initially all empty).\n",
        "\n",
        "for each i from 1 to n:\n",
        "  for each production rule A → wi:\n",
        "    add A to Ch(i, i+1)\n",
        "\n",
        "for each width b from 2 to n:\n",
        "  for each start position i from 1 to n-b+1:\n",
        "    for each left width k from 1 to b-1:\n",
        "      for each B ∈ Ch(i, i+k) and C ∈ Ch(i+k,i+b):\n",
        "        for each production rule A → B C: \n",
        "          add A to Ch(i,i+b)\n",
        "          \n",
        "claim that w ∈ L(G) iff S ∈ Ch(1,n+1)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQRmcNgJ2U70",
        "cellView": "code"
      },
      "source": [
        "def recognize_with_cky(sentence: Union[str, List[str]], grammar: CFG) -> bool:\n",
        "    \"\"\"\n",
        "    Recognises if the sentence words are valid in terms \n",
        "    of the chosen context-free grammar (CFG) in Chomsky normal form (CNF).\n",
        "\n",
        "    Basically, this function translates pseudocode from the lecture,\n",
        "    listed above, to the actual Python code.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_i_k_element_of_chart(chart: List[List[Set[Nonterminal]]], \n",
        "                                 i: int, k: int) -> Set[Nonterminal]:\n",
        "        \"\"\"\n",
        "        This function is a trick to map indices from pseudocode above \n",
        "        to the underlying Python representation of the chart.\n",
        "        \n",
        "        \"\"\"\n",
        "        n = len(chart)\n",
        "        return chart[n - k + 1][i - 1]\n",
        "\n",
        "    def update_i_k_element_chart(chart: List[List[Set[Nonterminal]]], \n",
        "                                 i: int, k: int, new_element: Nonterminal):\n",
        "        n = len(chart)\n",
        "        return chart[n - k + 1][i - 1].add(new_element)\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        sentence = [word.lower() for word in sentence.split(' ')]\n",
        "    \n",
        "    n = len(sentence)\n",
        "    # we need only top-left half of the n*n matrix for the chart\n",
        "    chart = [[set() for j in range(n-i)] for i in range(n)]\n",
        "\n",
        "    # for each i from 1 to n:\n",
        "    for i in range(1, n + 1):\n",
        "        cur_word = sentence[i - 1].lower()\n",
        "        # cnf_grammar.productions(rhs=sentence_words[i]) returns all \n",
        "        # only productions with the given first item in the right-hand side.\n",
        "\n",
        "        # for each production rule A → wi:\n",
        "        for production_rule in grammar.productions(rhs=cur_word):\n",
        "            # CNF guarantees that right-hand side is \n",
        "            # either exactly one terminal or exactly two non-terminals.\n",
        "            if len(production_rule.rhs()) > 1:\n",
        "                message = f'Provided grammar is not in CNF: {production_rule}'\n",
        "                raise Exception(message)\n",
        "\n",
        "            # Therefore, we do not have to filter out production rules\n",
        "            # given that 'cur_word' is a terminal.\n",
        "\n",
        "            # add A to Ch(i, i+1)\n",
        "            update_i_k_element_chart(chart, i, i + 1, production_rule.lhs())\n",
        "\n",
        "    # for each width b from 2 to n:\n",
        "    for b in range(2, n + 1):\n",
        "        # for each start position i from 1 to n-b+1:\n",
        "        for i in range(1, n - b + 2):\n",
        "            # for each left width k from 1 to b-1:\n",
        "            for k in range(1, b):\n",
        "                # for each B ∈ Ch(i, i+k) and C ∈ Ch(i+k,i+b):\n",
        "                left_nonterminals = \\\n",
        "                    get_i_k_element_of_chart(chart, i, i + k)\n",
        "                right_nonterminals = \\\n",
        "                    get_i_k_element_of_chart(chart, i + k, i + b)\n",
        "                if right_nonterminals:\n",
        "                    for left_nonterminal in left_nonterminals:\n",
        "                        # for each production rule A → B C:\n",
        "                        for candidate_rule in grammar.productions(rhs=left_nonterminal):\n",
        "                            if candidate_rule.rhs()[1] in right_nonterminals:\n",
        "                                # add A to Ch(i,i+b)\n",
        "                                update_i_k_element_chart(chart, i, i + b,\n",
        "                                                         candidate_rule.lhs())\n",
        "\n",
        "    # claim that w ∈ L(G) iff S ∈ Ch(1,n+1)\n",
        "    parsing_result = grammar.start() in get_i_k_element_of_chart(chart, 1, n + 1)\n",
        "    return parsing_result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVWgn2RoTXMO",
        "outputId": "3016159a-8f26-46be-8f28-519ced9338b6"
      },
      "source": [
        "sentence_parse_results = [recognize_with_cky(sentence, cnf_grammar) for sentence, num_parses in tqdm(t)]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [00:12<00:00,  7.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdgWbFSYTvXe",
        "outputId": "a34ae0ca-f55d-4e75-d2ef-817d80db7a84"
      },
      "source": [
        "print('Parsed count: ', sentence_parse_results.count(True))\n",
        "print('Non-parsed count: ', sentence_parse_results.count(False))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed count:  70\n",
            "Non-parsed count:  28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwdWheChUEt-"
      },
      "source": [
        "parsed_indices = [i for i in range(len(t)) if sentence_parse_results[i]]\n",
        "non_parsed_indices = [i for i in range(len(t)) if not sentence_parse_results[i]]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8pnfaIRUTzm",
        "outputId": "1034eaf9-2484-4406-b2a5-d3d807adefe0"
      },
      "source": [
        "for i in range(5):\n",
        "    print('Parsed sentence: ', \" \".join(t[parsed_indices[i]][0]))\n",
        "    print('Non-parsed sentence: ', \" \".join(t[non_parsed_indices[i]][0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed sentence:  i need a flight from charlotte to las vegas that makes a stop in saint louis .\n",
            "Non-parsed sentence:  what aircraft is this .\n",
            "Parsed sentence:  what is the cheapest one way flight from phoenix to san diego that arrives in the morning on thursday june second .\n",
            "Non-parsed sentence:  what flights are available between chicago and indianapolis next wednesday between eleven a.m. and one p.m .\n",
            "Parsed sentence:  what is the cheapest one way flight from columbus to indianapolis .\n",
            "Non-parsed sentence:  please book a one way coach fare from chicago to indianapolis on united flight two ninety two next wednesday .\n",
            "Parsed sentence:  is there a flight from memphis to los angeles .\n",
            "Non-parsed sentence:  show american flights after twelve p.m. from miami to chicago .\n",
            "Parsed sentence:  please show me the flights from chicago to detroit that arrive at six p.m. next tuesday .\n",
            "Non-parsed sentence:  does united flight four seven four slash fourteen eighty four serve dinner .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ_lLq9wYHDr"
      },
      "source": [
        "def check_test_sentences(sentences: Union[List[str], str]):\n",
        "    for sent in sentences:\n",
        "        parsing_result = recognize_with_cky(sent, cnf_grammar)\n",
        "        input_for_printing = ' '.join(sent) if not isinstance(sent, str) else sent\n",
        "\n",
        "        print('Input sentence: ', input_for_printing)\n",
        "        print('Parsing result: ', parsing_result)\n",
        "        print()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F7LJ1EYYR0T",
        "outputId": "04731502-46b3-4c28-ea14-9fddec21d934"
      },
      "source": [
        "my_test_sentences = [\n",
        "    ['fly', 'can', 'i', 'to', 'miami', '.'],\n",
        "    ['can', 'i', 'fly', 'to', 'miami', '.'],\n",
        "    ['can', 'i', 'fly', 'to', 'las', 'vegas', '.'],\n",
        "    ['show', 'me', 'the', 'plane', 'to', 'miami', '.'],\n",
        "]\n",
        "\n",
        "check_test_sentences(my_test_sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence:  fly can i to miami .\n",
            "Parsing result:  False\n",
            "\n",
            "Input sentence:  can i fly to miami .\n",
            "Parsing result:  False\n",
            "\n",
            "Input sentence:  can i fly to las vegas .\n",
            "Parsing result:  False\n",
            "\n",
            "Input sentence:  show me the plane to miami .\n",
            "Parsing result:  True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTcf5qi8Zhx9"
      },
      "source": [
        "I do not know why but perfectly correct sentences like 'can i fly to miami .' are getting rejected. \n",
        "\n",
        "Whereas their rephrasings ('show me the plane to miami .') are getting accepted. \n",
        "\n",
        "I reckon this is the grammar-dependent issue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiX4JEEFYUNr",
        "outputId": "fe0ae0a5-1a9e-4f04-a33a-5edc24eecaf7"
      },
      "source": [
        "my_test_sentences = [\n",
        "    'what is the price .',\n",
        "    'what is the price ?',\n",
        "    'what is a price .',\n",
        "    'is what a price .',\n",
        "    'is price a what .',\n",
        "    'is price a what .',\n",
        "]\n",
        "\n",
        "check_test_sentences(my_test_sentences)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence:  what is the price .\n",
            "Parsing result:  True\n",
            "\n",
            "Input sentence:  what is the price ?\n",
            "Parsing result:  False\n",
            "\n",
            "Input sentence:  what is a price .\n",
            "Parsing result:  True\n",
            "\n",
            "Input sentence:  is what a price .\n",
            "Parsing result:  True\n",
            "\n",
            "Input sentence:  is price a what .\n",
            "Parsing result:  True\n",
            "\n",
            "Input sentence:  is price a what .\n",
            "Parsing result:  True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpD8nl5CZNxq"
      },
      "source": [
        "Two general comments based on results:\n",
        "\n",
        "1. Short sentencies are easier to accept as parsed, since we have not so much production rules applied.\n",
        "2. This grammar does not know question mark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNExgKZLYWHa",
        "outputId": "a5e244fc-16dd-4a35-8027-3e6ad8e779b2"
      },
      "source": [
        "my_test_sentences = [\n",
        "    'show me cheap flights to miami .',\n",
        "    'show me flights cheap to miami .',\n",
        "     \n",
        "    'me flights cheap to miami show .',\n",
        "]\n",
        "\n",
        "check_test_sentences(my_test_sentences)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sentence:  show me cheap flights to miami .\n",
            "Parsing result:  True\n",
            "\n",
            "Input sentence:  show me flights cheap to miami .\n",
            "Parsing result:  True\n",
            "\n",
            "Input sentence:  me flights cheap to miami show .\n",
            "Parsing result:  False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-BqHw_aZ6Hb"
      },
      "source": [
        "Absolutely correct sentence is parsed ('show me cheap flights to miami .').\n",
        "\n",
        "Additionally, the slightly ungrammatical sentence ('show me flights cheap to miami .') is parsed either. I assume that the grammar here knows transition like NP -> N ADJ as well as NP -> ADJ N. The other parts of the parsing algorithm will be the same.\n",
        "\n",
        "Nevertheless, if we make the sentence 'too' ungrammatical ('me flights cheap to miami show .'), it is no more getting parsed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h-qYrXf2aq5"
      },
      "source": [
        "## Parser\n",
        "\n",
        "Now extend your CKY recognizer into a parser by adding backpointers. Also implement a function that extracts the set of all parse trees from the backpointers in the chart. Feel free to use the NLTK module\n",
        "nltk.tree for this purpose; notice that only ImmutableTrees can be used\n",
        "as elements of Python sets, whereas raw Trees cannot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1tC_h0MyfbS"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuX48BwZ2lQX"
      },
      "source": [
        "## Submission guideline\n",
        "\n",
        "Submit your code, outputs, and a README file. The outputs should consist\n",
        "of at least:\n",
        "\n",
        "(1) your parsing results (number of parses per sentence), as a\n",
        "text file with one line of the form sentence\\t#parses for each test sentence,\n",
        "where \\t is a tab character; \n",
        "\n",
        "(2) pictures of the parse trees for an ATIS test\n",
        "sentence with two to five parses. You can visualize an NLTK tree using its\n",
        "draw method, and check your parse tree counts against the counts in NLTK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz-b-_rg24zp"
      },
      "source": [
        "## Extra credit \n",
        "\n",
        "If you still have time left, here’s a project for extra credit.\n",
        "\n",
        "Perhaps it has occurred to you that it is quite wasteful to compute all parse\n",
        "trees just to find out how many parse trees there are. Figure out how to\n",
        "compute the number of parse trees for an entry A ∈ Ch(i, k) from your chart\n",
        "with backpointers, without actually computing these parse trees. Verify that\n",
        "you get the correct results, and compare the efficiency of your new procedure\n",
        "to your earlier solution."
      ]
    }
  ]
}