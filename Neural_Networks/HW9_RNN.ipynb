{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13935de6-9e28-4f76-83da-6f72218e3bef",
      "metadata": {
        "id": "13935de6-9e28-4f76-83da-6f72218e3bef"
      },
      "source": [
        "# NNIA Assignment 9\n",
        "\n",
        "**DEADLINE: 26. 1. 2022 08:00 CET**\n",
        "Submission more than 10 minutes past the deadline will **not** be graded!\n",
        "\n",
        "- Trevor Atkins & trat00001@uni-saarland.de:\n",
        "- Tsimafei Prakapenka & tspr00001@uni-saarland.de:\n",
        "- Hours of work per person: Prakapenka ~9.5h Atkins ~4.5h\n",
        "- Group nickname: PraAt\n",
        "\n",
        "# Submission Instructions\n",
        "\n",
        "**IMPORTANT** Please make sure you read the following instructions carefully. If you are unclear about any part of the assignment, ask questions **before** the assignment deadline. All course-related questions can be addressed on the course **[Piazza Platform](https://piazza.com/class/kvc3vzhsvh55rt)**.\n",
        "\n",
        "* Assignments are to be submitted in a **team of 2**.\n",
        "* Please include your **names**, **ID's**, **Teams usernames**, and **approximate total time spent per person** at the beginning of the Notebook in the space provided\n",
        "* Make sure you appropriately comment your code wherever required.\n",
        "* Your final submission should contain this completed Jupyter Notebook, including the bonus question (if you attempt it), and any necessary Python files.\n",
        "* Do **not** submit any data or cache files (e.g. `__pycache__`).\n",
        "* Upload the **zipped** folder (*.zip* is the only accepted extension) in **Teams**.\n",
        "* Only **one member** of the group should make the submisssion.\n",
        "* **Important** please name the submitted zip folder as: `Name1_id1_Name2_id2.zip`. The Jupyter Notebook should also be named: `Name1_id1_Name2_id2.ipynb`. This is **very important** for our internal organization epeatedly students fail to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "feef094d-d753-4e3d-b5ef-d720810dae31",
      "metadata": {
        "id": "feef094d-d753-4e3d-b5ef-d720810dae31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3481f160-60be-46b3-8ce1-b6082057f5fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c30bb375-058c-4253-aa17-7adfa4ea2ab6",
      "metadata": {
        "id": "c30bb375-058c-4253-aa17-7adfa4ea2ab6"
      },
      "source": [
        "# 1 Diacritization (9 points)\n",
        "\n",
        "The English alphabet has 26 letters. This is not the case for Czech (and many more European languages), which has many more extra letters, namely those with a simple accent (čárka, lit. \"short line segment\"): `áéíýúó`, those with a little hook (háček): `ěčšžř` and those with a circle (kroužek) `ů`.\n",
        "They change the pronounciations of the words (mostly palatalization) and also distinguish words (there are many words which differ only by diacritics). \n",
        "Typing words without these accents is considered to be rude (and annoying to read).\n",
        "Imagine you've been tasked by a telecommunication company to come up with a system to automatically add all the accents correctly given a word without accents.\n",
        "Each line in the input contains two words: with and without accents, e.g.: `cerveneho červeného`.\n",
        "We provide the train/dev split for you (in separate files) and also a test file without correct answers.\n",
        "\n",
        "Your task is to create two neural networks character-level models that add the diacritization back to the word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54ae1d3a",
      "metadata": {
        "id": "54ae1d3a"
      },
      "source": [
        "## 1.1 Baseline (1 points)\n",
        "\n",
        "- Plot the distribution of classes (there are 4)\n",
        "- Evaluate the accuracy of most common class classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2c8b7e43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c8b7e43",
        "outputId": "bba7fc39-840c-4617-813d-ee3a99be5e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Using cached wget-3.2-py3-none-any.whl\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "! pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "eab3e779",
      "metadata": {
        "id": "eab3e779"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "LXWvFr7EvW_j",
      "metadata": {
        "id": "LXWvFr7EvW_j"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('solution.py'):\n",
        "    wget.download('https://raw.githubusercontent.com/tsimafeip/LCT-master-course/main/Neural_Networks/HW9_solution.py', 'solution.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6050e91f",
      "metadata": {
        "id": "6050e91f"
      },
      "outputs": [],
      "source": [
        "from solution import download_data_files\n",
        "\n",
        "train_filename = 'words_random_train.txt'\n",
        "dev_filename = 'words_random_dev.txt'\n",
        "test_filename = 'words_random_test_blind.txt'\n",
        "\n",
        "download_data_files([train_filename, dev_filename, test_filename])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d62a8930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d62a8930",
        "outputId": "4feb77ab-a9d3-4be1-c9a3-8b608040b58f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nájemřidiči', 'najemridici'] ['neodmyslitelné', 'neodmyslitelne'] transvestite\n"
          ]
        }
      ],
      "source": [
        "with open(train_filename, \"r\") as f:\n",
        "    train_data = list(map(str.split, f.readlines()))\n",
        "\n",
        "with open(dev_filename, \"r\") as f:\n",
        "    dev_data = list(map(str.split, f.readlines()))\n",
        "\n",
        "with open(test_filename, \"r\") as f:\n",
        "    test_data = [line.strip() for line in f.readlines()]\n",
        "\n",
        "print(train_data[1], dev_data[1], test_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eb910f12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb910f12",
        "outputId": "5a5ae59f-f554-4d43-b123-b7d5abde0a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'á': 1, 'é': 1, 'í': 1, 'ý': 1, 'ú': 1, 'ó': 1, 'ě': 2, 'č': 2, 'š': 2, 'ž': 2, 'ř': 2, 'ů': 3})\n"
          ]
        }
      ],
      "source": [
        "classlabel_to_classname = {0: 'nothing', 1: 'čárka', 2: 'háček', 3: 'kroužek'}\n",
        "classlabel_to_char = {1: ['á','é','í','ý','ú','ó'], 2: ['ě','č','š','ž','ř'], 3: ['ů']}\n",
        "\n",
        "# I use defaultdict to handle 0-class more smoothly\n",
        "char_to_classlabel = defaultdict(int)\n",
        "char_to_classlabel.update({\n",
        "    class_char: class_label \n",
        "    for class_label, class_chars in classlabel_to_char.items() \n",
        "    for class_char in class_chars\n",
        "})\n",
        "print(char_to_classlabel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "04aacd5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "04aacd5b",
        "outputId": "4799b64a-757e-4f43-d571-393482b435ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nothing': 1021576, 'čárka': 78545, 'háček': 42728, 'kroužek': 2601}\n",
            "{'nothing': 0.8918556026015976, 'čárka': 0.06857130385438037, 'háček': 0.03730237024750098, 'kroužek': 0.002270723296521018}\n"
          ]
        }
      ],
      "source": [
        "from solution import distribution\n",
        "\n",
        "classname_to_count = distribution(\n",
        "    train_data=train_data, \n",
        "    classlabel_to_classname=classlabel_to_classname, \n",
        "    char_to_classlabel=char_to_classlabel,\n",
        ")\n",
        "print(classname_to_count)\n",
        "\n",
        "all_count = sum(classname_to_count.values())\n",
        "classname_to_percentage = {\n",
        "    class_name: class_count/all_count \n",
        "    for class_name, class_count in classname_to_count.items()\n",
        "}\n",
        "print(classname_to_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "989c3fa0",
      "metadata": {
        "id": "989c3fa0"
      },
      "source": [
        "So, defaulting to nothing class will give us ~0.89 accuracy. Definitely not bad for a start."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6769e4c5",
      "metadata": {
        "id": "6769e4c5"
      },
      "source": [
        "## 1.2 Sliding windows (3 points)\n",
        "\n",
        "The first model is based on sliding windows, e.g. it considers the current character and two characters to the left and two characters to the right for context.\n",
        "You should also add padding tokens to the left and to the right so that you can classify the corner characters as well:\n",
        "\n",
        "```\n",
        "__Cer -> HOOK\n",
        "_cErv -> NOTHING\n",
        "ceRve -> NOTHING\n",
        "erVen -> NOTHING\n",
        "rvEne -> NOTHING\n",
        "veNeh -> NOTHING\n",
        "enEho -> SIMPLE ACCENT\n",
        "neHo_ -> NOTHING\n",
        "ehO__ -> NOTHING\n",
        "```\n",
        "\n",
        "\n",
        "Build a sliding-window neural network with the best architecture and hyperparameters and report your accuracies on train and dev datasets.\n",
        "Additionally, provide the output for the test file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "LV4GxxxnCDeR",
      "metadata": {
        "id": "LV4GxxxnCDeR"
      },
      "outputs": [],
      "source": [
        "#Global params\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PADDING_SYMBOL = \"_\"\n",
        "ALPHABET_SIZE = 26\n",
        "\n",
        "#Common NN params\n",
        "NUM_CLASSES = 4\n",
        "DROPOUT = 0.25\n",
        "\n",
        "# FFNN params\n",
        "FORCE_RETRAIN_FFNN = False\n",
        "FFNN_BEST_MODEL_PATH = 'best-model-ffnn.pt'\n",
        "FFNN_EPOCHS = 50\n",
        "FFNN_BATCH_SIZE = 128\n",
        "FFNN_INPUT_SIZE = 130\n",
        "\n",
        "# RNN params\n",
        "FORCE_RETRAIN_RNN = True\n",
        "RNN_BEST_MODEL_PATH = 'best-model-rnn.pt'\n",
        "RNN_EPOCHS = 30\n",
        "RNN_HIDDEN_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "tw4azp968ZXz",
      "metadata": {
        "id": "tw4azp968ZXz"
      },
      "outputs": [],
      "source": [
        "from solution import prepare_sliding_data\n",
        "\n",
        "X_train, y_train = prepare_sliding_data(train_data, char_to_classlabel)\n",
        "X_dev, y_dev = prepare_sliding_data(dev_data, char_to_classlabel)\n",
        "X_test = prepare_sliding_data(test_data, char_to_classlabel)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ba638fd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba638fd4",
        "outputId": "421bf7f4-511a-4746-efc2-ed1208bafa47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('__nei', 0, 1145450, 190499, 169901)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train[0], y_train[0], len(X_train), len(X_dev), len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e948567d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e948567d",
        "outputId": "9c279fcc-77a6-4b55-e065-0c0d5730108f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__nei 130\n"
          ]
        }
      ],
      "source": [
        "from solution import one_hot_encode\n",
        "\n",
        "sample_encoding = one_hot_encode(X_train[0])\n",
        "print(X_train[0], len(sample_encoding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "80728d95",
      "metadata": {
        "id": "80728d95"
      },
      "outputs": [],
      "source": [
        "from solution import CustomSlidingDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = CustomSlidingDataset(X_train, y_train)\n",
        "validation_dataset = CustomSlidingDataset(X_dev, y_dev)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=FFNN_BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=FFNN_BATCH_SIZE*4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "CGtODtRQ6C4j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGtODtRQ6C4j",
        "outputId": "47c88d29-3d4c-4e87-f240-985e2d2bdb5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 373/373 [00:01<00:00, 190.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'loss': 0.10484777705559142, 'accuracy': 0.9600050393965323, 'predicted_labels': defaultdict(<class 'int'>, {0: 173081, 1: 11157, 2: 5972, 3: 289}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from solution import run_train_and_val_ffnn, DiacriticFFNN, validation_loop_ffnn\n",
        "\n",
        "\n",
        "if not FORCE_RETRAIN_FFNN and not os.path.isfile(FFNN_BEST_MODEL_PATH):\n",
        "    wget.download(f'https://raw.githubusercontent.com/tsimafeip/LCT-master-course/main/Neural_Networks/HW9_data/{FFNN_BEST_MODEL_PATH}', FFNN_BEST_MODEL_PATH)\n",
        "    model = DiacriticFFNN().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(FFNN_BEST_MODEL_PATH, map_location=DEVICE))\n",
        "    # run short validation to report metrics and check if model is working\n",
        "    ffnn_best_metrics = \\\n",
        "        validation_loop_ffnn(model=model, \n",
        "                             dataloader=validation_dataloader, \n",
        "                             loss_fn = nn.CrossEntropyLoss())\n",
        "    print()\n",
        "    print(ffnn_best_metrics)\n",
        "\n",
        "if FORCE_RETRAIN_FFNN or not os.path.isfile(FFNN_BEST_MODEL_PATH):\n",
        "    model = DiacriticFFNN()\n",
        "    ffnn_best_model_path, ffnn_best_epoch, ffnn_best_metrics = \\\n",
        "        run_train_and_val_ffnn(model, train_dataloader,\n",
        "                               validation_dataloader,\n",
        "                               epochs=FFNN_EPOCHS,\n",
        "                               best_model_path=FFNN_BEST_MODEL_PATH)\n",
        "    \n",
        "    print()\n",
        "    print(ffnn_best_model_path, ffnn_best_epoch, ffnn_best_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "LQxwS080I8L4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQxwS080I8L4",
        "outputId": "d99c265d-7e55-4656-fbc7-281978cd7053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169901/169901 [01:21<00:00, 2097.21it/s]\n"
          ]
        }
      ],
      "source": [
        "from solution import predict_result_fnn\n",
        "          \n",
        "predict_result_fnn(X_test, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b2d1ba1",
      "metadata": {
        "id": "5b2d1ba1"
      },
      "source": [
        "## 1.3 RNN (5 points)\n",
        "\n",
        "Secondly, build a character-level recurrent neural network many (n) to many (n) which performs the classification:\n",
        "```\n",
        "cerveny -> HNNNNNANN\n",
        "```\n",
        "\n",
        "Be careful, this will require you to either pad the input sequence (then you will also need to backpropagate only from the original sequence and disregard padded values) or use some other trick.\n",
        "\n",
        "You can use all the tricks you know for both models. For the RNN-based one, you can use non-vanilla RNN cells (such as LSTM or GRU). The recurrent part should be followed-up with a classification FFNN. Again, try to find the best architecture and hyperparameters, report train and dev results.\n",
        "\n",
        "In both cases, describe in text the architecture of your models.\n",
        "\n",
        "Provide also an output for the test file, one word per file, with diacritics (e.g. `červeného`). This is mandatory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "06c81049",
      "metadata": {
        "id": "06c81049"
      },
      "outputs": [],
      "source": [
        "from solution import prepare_rnn_data\n",
        "\n",
        "X_train_rnn, y_train_rnn = prepare_rnn_data(train_data, char_to_classlabel)\n",
        "X_dev_rnn, y_dev_rnn = prepare_rnn_data(dev_data, char_to_classlabel)\n",
        "X_test_rnn = prepare_rnn_data(test_data, char_to_classlabel)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "51401bc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51401bc0",
        "outputId": "d2d9b890-de9f-4ac8-f6dc-f8b62a00003b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90000, 15000, 13376, tensor([0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(X_train_rnn), len(X_dev_rnn), len(X_test_rnn), y_train_rnn[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7EwSlaDFKqWt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EwSlaDFKqWt",
        "outputId": "6410f011-5c61-4cd8-b141-d64a88da5556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 26]) torch.Size([11, 4])\n"
          ]
        }
      ],
      "source": [
        "from solution import DiacriticsRNN\n",
        "\n",
        "rnn_model = DiacriticsRNN(input_size=ALPHABET_SIZE, hidden_size=RNN_HIDDEN_SIZE,\n",
        "                          output_size=NUM_CLASSES, dropout=DROPOUT)\n",
        "\n",
        "# check if forward path works\n",
        "for input_tensor in X_train_rnn:\n",
        "    with torch.no_grad():\n",
        "        model_output = rnn_model.forward(input_tensor)\n",
        "        print(input_tensor.shape, model_output.shape)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "72403c0d",
      "metadata": {
        "id": "72403c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f97b6b3-d49f-4e1e-9255-c0fa3cae9d43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:37, 266.76it/s]\n",
            "15000it [00:11, 1322.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.4001244083625782, 'accuracy': 0.8882098738487058, 'predicted_labels': defaultdict(<class 'int'>, {2: 888, 1: 2968, 3: 1672, 0: 1139922}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.31458890340297174, 'accuracy': 0.8931700428873642, 'predicted_labels': defaultdict(<class 'int'>, {0: 190499}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "1 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:34, 269.05it/s]\n",
            "15000it [00:11, 1336.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.2882971805836902, 'accuracy': 0.9053664498668645, 'predicted_labels': defaultdict(<class 'int'>, {0: 1110958, 1: 34492}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.25653194451220335, 'accuracy': 0.9171964157292164, 'predicted_labels': defaultdict(<class 'int'>, {0: 182559, 1: 7940}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "2 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:30, 272.01it/s]\n",
            "15000it [00:10, 1378.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.24769366384181193, 'accuracy': 0.9158610153214893, 'predicted_labels': defaultdict(<class 'int'>, {0: 1090657, 1: 54544, 2: 249}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.22640131444294626, 'accuracy': 0.9195113885112258, 'predicted_labels': defaultdict(<class 'int'>, {0: 181687, 1: 8797, 2: 15}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "3 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:33, 269.71it/s]\n",
            "15000it [00:11, 1343.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.22449429265559495, 'accuracy': 0.9197861102623424, 'predicted_labels': defaultdict(<class 'int'>, {0: 1084672, 1: 57605, 2: 3173}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.20852729925091068, 'accuracy': 0.9236163969364669, 'predicted_labels': defaultdict(<class 'int'>, {0: 180797, 1: 9120, 2: 582}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "4 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:32, 270.34it/s]\n",
            "15000it [00:11, 1346.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.21011506761838553, 'accuracy': 0.9228792177746737, 'predicted_labels': defaultdict(<class 'int'>, {0: 1079033, 1: 58544, 2: 7873}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.1967005218398602, 'accuracy': 0.9267030273124793, 'predicted_labels': defaultdict(<class 'int'>, {0: 179803, 2: 1421, 1: 9275}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "5 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:32, 270.85it/s]\n",
            "15000it [00:11, 1358.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.20019655557393173, 'accuracy': 0.9253699419442141, 'predicted_labels': defaultdict(<class 'int'>, {0: 1074333, 1: 58949, 2: 12167, 3: 1}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.18885227981875652, 'accuracy': 0.9291124887794686, 'predicted_labels': defaultdict(<class 'int'>, {0: 179510, 2: 2010, 1: 8979}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "6 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:34, 269.42it/s]\n",
            "15000it [00:11, 1353.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.19376835391379588, 'accuracy': 0.9271046313675848, 'predicted_labels': defaultdict(<class 'int'>, {0: 1071120, 2: 15188, 1: 59128, 3: 14}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.18309228403560507, 'accuracy': 0.931122998020987, 'predicted_labels': defaultdict(<class 'int'>, {0: 178946, 2: 2417, 1: 9136}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "7 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:35, 268.48it/s]\n",
            "15000it [00:11, 1363.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.1885815920424224, 'accuracy': 0.9286638439041425, 'predicted_labels': defaultdict(<class 'int'>, {0: 1068630, 2: 17381, 1: 59399, 3: 40}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.1786643839006196, 'accuracy': 0.9327030588087076, 'predicted_labels': defaultdict(<class 'int'>, {0: 178492, 2: 2781, 1: 9226}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "8 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:34, 269.27it/s]\n",
            "15000it [00:10, 1368.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.18452603743321072, 'accuracy': 0.9299934523549697, 'predicted_labels': defaultdict(<class 'int'>, {0: 1066983, 2: 18848, 1: 59544, 3: 75}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.1751255015146744, 'accuracy': 0.9343461120530816, 'predicted_labels': defaultdict(<class 'int'>, {0: 177959, 2: 3143, 1: 9394, 3: 3}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "9 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:32, 270.58it/s]\n",
            "15000it [00:11, 1323.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.18110033512433488, 'accuracy': 0.9310340914051246, 'predicted_labels': defaultdict(<class 'int'>, {0: 1065002, 2: 20194, 1: 60131, 3: 123}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.17211155427772318, 'accuracy': 0.9352175077034525, 'predicted_labels': defaultdict(<class 'int'>, {0: 177839, 2: 3245, 1: 9412, 3: 3}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "10 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:37, 266.76it/s]\n",
            "15000it [00:11, 1313.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.17840133032429262, 'accuracy': 0.9319193330132263, 'predicted_labels': defaultdict(<class 'int'>, {0: 1064219, 2: 20921, 1: 60152, 3: 158}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.16936015812135496, 'accuracy': 0.9362358857526811, 'predicted_labels': defaultdict(<class 'int'>, {0: 177559, 2: 3416, 1: 9519, 3: 5}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "11 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "90000it [05:35, 268.12it/s]\n",
            "15000it [00:10, 1366.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Train metrics:  {'loss': 0.175665783823128, 'accuracy': 0.9331354489501943, 'predicted_labels': defaultdict(<class 'int'>, {0: 1063127, 2: 21674, 1: 60449, 3: 200}), 'gold_labels': defaultdict(<class 'int'>, {0: 1021576, 1: 78545, 2: 42728, 3: 2601})}\n",
            "Validation metrics:  {'loss': 0.16698830330783676, 'accuracy': 0.9373330043727264, 'predicted_labels': defaultdict(<class 'int'>, {0: 177305, 2: 3462, 1: 9723, 3: 9}), 'gold_labels': defaultdict(<class 'int'>, {0: 170148, 1: 12887, 2: 7002, 3: 462})}\n",
            "\n",
            "-------------------------------\n",
            "12 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2908it [00:10, 264.80it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-89274bd200d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                               \u001b[0my_train_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_dev_rnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                               \u001b[0my_dev_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRNN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                               path_to_best_model_file=RNN_BEST_MODEL_PATH)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/solution.py\u001b[0m in \u001b[0;36mrun_train_and_val_rnn\u001b[0;34m(model, x_train, y_train, x_val, y_val, epochs, path_to_best_model_file, learning_rate)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcur_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loop_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/solution.py\u001b[0m in \u001b[0;36mtrain_loop_rnn\u001b[0;34m(x_data, y_data, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_label_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Compute prediction and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mpred_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_label_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/solution.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embedded_input)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# predictions has shape (1, sequence_len, num_classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# reshaping to remove artificial batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from solution import run_train_and_val_rnn, validation_loop_rnn\n",
        "\n",
        "if not FORCE_RETRAIN_RNN and not os.path.isfile(RNN_BEST_MODEL_PATH):\n",
        "    wget.download(f'https://raw.githubusercontent.com/tsimafeip/LCT-master-course/main/Neural_Networks/HW9_data/{RNN_BEST_MODEL_PATH}', RNN_BEST_MODEL_PATH)\n",
        "    rnn_model = DiacriticsRNN()\n",
        "    rnn_model.load_state_dict(torch.load(RNN_BEST_MODEL_PATH, map_location=DEVICE))\n",
        "    # run short validation to report metrics and check if model is working\n",
        "    best_rnn_metrics = \\\n",
        "        validation_loop_rnn(model=rnn_model, x_data=X_dev_rnn, \n",
        "                            y_data=y_dev_rnn, loss_fn = nn.CrossEntropyLoss())\n",
        "    \n",
        "    print()\n",
        "    print(best_rnn_metrics)\n",
        "\n",
        "if FORCE_RETRAIN_RNN or not os.path.isfile(RNN_BEST_MODEL_PATH):\n",
        "    rnn_model = DiacriticsRNN(input_size=ALPHABET_SIZE, hidden_size=RNN_HIDDEN_SIZE,\n",
        "                              output_size=NUM_CLASSES, dropout=DROPOUT)\n",
        "\n",
        "    path_to_best_rnn_model_file, best_rnn_epoch, best_rnn_metrics = \\\n",
        "        run_train_and_val_rnn(rnn_model, X_train_rnn,\n",
        "                              y_train_rnn, X_dev_rnn,\n",
        "                              y_dev_rnn, epochs=RNN_EPOCHS,\n",
        "                              path_to_best_model_file=RNN_BEST_MODEL_PATH)\n",
        "    \n",
        "    print()\n",
        "    print(path_to_best_rnn_model_file, best_rnn_epoch, best_rnn_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5a3c01f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "5a3c01f8",
        "outputId": "ea757031-ae04-4a0e-fa30-5d669a75d758"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-dcbfaa0987c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_result_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredict_result_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_best_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_best_rnn_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'path_to_best_rnn_model_file' is not defined"
          ]
        }
      ],
      "source": [
        "from solution import predict_result_rnn      \n",
        "          \n",
        "predict_result_rnn(test_data, X_test_rnn, rnn_model, path_to_best_model=path_to_best_rnn_model_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bfbdf7d-6c39-4eba-8b18-8cf8b8d86d8b",
      "metadata": {
        "id": "0bfbdf7d-6c39-4eba-8b18-8cf8b8d86d8b"
      },
      "source": [
        "# 2 Theory (1 point)\n",
        "\n",
        "Find NLP tasks (apart form diacritization) that match the following RNN architecture and describe them in detail:\n",
        "- Many (n) to many (n)\n",
        "- Many (n) to many (m), m $\\neq$ n\n",
        "- Many (n) to one\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64cd25f",
      "metadata": {
        "id": "f64cd25f"
      },
      "source": [
        "- Many (n) to many (n) - POS-tagging <br>\n",
        "This RNN has synced sequence input and synced sequence output where both lengths are equal. For POS-tagging for example, word tokennization is processed on a sentence and a POS will be tagged for each token. \n",
        "Example: sentence: computational linguistics is interdisciplinary\n",
        "tokenization: \\['computational', 'linguistics', 'is', 'interdisciplinary'\\]\n",
        "pos-tag: \\['adjective', 'noun', 'verb', 'adjective'\\] Each output node can measure the loss, so averaging the losses (sequence loss) can be used for training. Padding tokens may need to be considered for removal.\n",
        "- Many (n) to many (m), m $\\neq$ n - Machine Translation <br>\n",
        "This RNN has sequence input and sequence output. For machine translation, the RNN has LSTM layers or architecture, where there is a self-loop with gated weights (forget gate, external input gate, and output gate). Cells are connected recurrently to each other, replacing the usual hidden units of ordinary recurrent networks. The layer is also split into two parts: the encoder that takes the input and the decoder that reads and translates to the output target language. \n",
        "- Many (n) to one - Sentiment Analysis <br>\n",
        "This RNN has sequence input and fixed size (one) output. For sentiment analysis, the input would be a sequence like a sentence and the output would be a classification label of positive or negative sentiment. The sentence would be converted into a numerical vector using an embedding layer and encoded with a bidirectional RNN. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6226bf7d-b8e9-4b3e-bf9f-d237b3ce8f41",
      "metadata": {
        "id": "6226bf7d-b8e9-4b3e-bf9f-d237b3ce8f41"
      },
      "source": [
        "# Final remarks\n",
        "\n",
        "## Accuracies\n",
        "\n",
        "It is important that your models perform well:\n",
        "\n",
        "||Dev accuracy|\n",
        "|-|-|\n",
        "|Minimum for full points on sliding windows|96.0%|\n",
        "|Minimum for full points on RNN|97.0%|\n",
        "|SoTA [Náplava et al. 2021](https://ufal.mff.cuni.cz/pbml/116/art-naplava-straka-strakova.pdf)|99.2% (different dataset)|\n",
        "|Best student solution from Charles University|99.1% (different dataset)|\n",
        "|A foreign student living in Prague for 5 years|92.0% (Vilém's personal feeling)|\n",
        "\n",
        "We will evaluate your test results and top 2 groups will get +2 points.\n",
        "The next 2 groups will get +1 point.\n",
        "\n",
        "## Runtime\n",
        "\n",
        "You don't need to use a GPU.\n",
        "The training on a 2019 high-end CPU takes 60 minutes.\n",
        "If you really need more compute power (you shouldn't need to need it) then you can use Google collab.\n",
        "Nevertheless, we suggest you to first work on a subset of data for a faster development loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234378ea",
      "metadata": {
        "id": "234378ea"
      },
      "outputs": [],
      "source": [
        "! rm $train_filename $dev_filename $test_filename rnn_predictions.txt sliding_predictions.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "assignment_9 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}